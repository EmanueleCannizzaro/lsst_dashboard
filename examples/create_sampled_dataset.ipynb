{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a copy of the Dataset class from lsst_dashboard.dataset\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from lsst.daf.persistence import Butler\n",
    "except ImportError:\n",
    "    Butler = None\n",
    "\n",
    "METADATA_FILENAME = 'metadata.yaml'\n",
    "\n",
    "def _default_metrics():\n",
    "    return [\n",
    "        'base_Footprint_nPix', 'Gaussian-PSF_magDiff_mmag', 'CircAper12pix-PSF_magDiff_mmag', \n",
    "        'Kron-PSF_magDiff_mmag', 'CModel-PSF_magDiff_mmag', 'traceSdss_pixel', 'traceSdss_fwhm_pixel', \n",
    "        'psfTraceSdssDiff_percent', 'e1ResidsSdss_milli', 'e2ResidsSdss_milli', 'deconvMoments', \n",
    "        'compareUnforced_Gaussian_magDiff_mmag', 'compareUnforced_CircAper12pix_magDiff_mmag', \n",
    "        'compareUnforced_Kron_magDiff_mmag', 'compareUnforced_CModel_magDiff_mmag'\n",
    "    ]\n",
    "\n",
    "def _default_flags():\n",
    "    return [\n",
    "        'calib_psf_used', 'calib_psf_candidate', 'calib_photometry_reserved', 'merge_measurement_i2', \n",
    "        'merge_measurement_i', 'merge_measurement_r2', 'merge_measurement_r', 'merge_measurement_z', \n",
    "        'merge_measurement_y', 'merge_measurement_g', 'merge_measurement_N921', 'merge_measurement_N816', \n",
    "        'merge_measurement_N1010', 'merge_measurement_N387', 'merge_measurement_N515', 'qaBad_flag'\n",
    "    ]\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, path):\n",
    "        self.path = Path(path)\n",
    "        self.metadata_path = self.path.joinpath(METADATA_FILENAME)\n",
    "        self.conn = None\n",
    "        self.metadata = None\n",
    "        self.tables = {}\n",
    "    \n",
    "    def connect(self):\n",
    "        if not self.path.joinpath('metadata.yaml').exists(): # todo: remove this once we have metadata yaml files saved in the data folders\n",
    "            self.metadata = {'metrics': _default_metrics(), 'flags': _default_flags()}\n",
    "        else:\n",
    "            with self.metadata.open('r') as f:\n",
    "                self.metadata = json.load(f)\n",
    "\n",
    "        # if Butler is available use it to connect. If not available we are reading from disk\n",
    "        if Butler: # \n",
    "            self.conn = Butler(str(self.path))\n",
    "\n",
    "    def get_table(self, table, tract, filt, sample=None):\n",
    "        if self.conn:\n",
    "            df = self.conn.get(table, tract=int(tract), filter=filt)\n",
    "        else: \n",
    "            raise NotImplementedError\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fetch_tables(self, tables=None, tracts=None, filters=None, metrics=None, sample=None):\n",
    "\n",
    "        if tables is None:\n",
    "            tables = self.metadata['tables']\n",
    "\n",
    "        if tracts is None:\n",
    "            tracts = self.metadata['tracts']\n",
    "\n",
    "        if filters is None:\n",
    "            filters = self.metadata['filters']\n",
    "\n",
    "        if metrics is None:\n",
    "            metrics = self.metadata['metrics']\n",
    "\n",
    "        dataset = {}\n",
    "        for filt in filters:\n",
    "            dataset[filt] = {}\n",
    "            for table in tables:\n",
    "                dataset[filt][table] = {}\n",
    "                for tract in tracts:\n",
    "                    print(f'filt={filt}, table={table}, tract={tract}')\n",
    "                    dataset[filt][table][tract] = self.get_table(table, tract, filt, sample)\n",
    "                    if 'coadd' in table.lower():\n",
    "                        df = dataset[filt][table][tract].toDataFrame(columns=metrics)\n",
    "                    else:\n",
    "                        df = dataset[filt][table][tract].toDataFrame()\n",
    "                    \n",
    "                    if sample:\n",
    "                        df = df.sample(sample)\n",
    "                    dataset[filt][table][tract] = df\n",
    "\n",
    "        self.tables = dataset\n",
    "\n",
    "    def fetch_visit(self, visit, tract, filt, sample=None):\n",
    "        df = self.conn.get('analysisVisitTable', visit=int(visit), tract=int(tract), filter=filt).toDataFrame(self.metadata['metrics'])\n",
    "        if sample:\n",
    "            df = df.sample(sample)\n",
    "        return df\n",
    "\n",
    "    def fetch_visits(self, tracts, filters, sample=None):\n",
    "        self.visits = {}\n",
    "        for filt in filters:\n",
    "            self.visits[filt] = {}\n",
    "            for tract in tracts:\n",
    "                print(f'filt={filt}, tract={tract}')\n",
    "                visits = pd.concat({str(visit): self.fetch_visit(visit, tract, filt, sample) for visit in self.tables[filt]['visitMatchTable'][tract]['matchId'].columns.astype(str)})\n",
    "                # leave this transform for later so we can save a simpler file\n",
    "                # visits = visits.set_index(pd.MultiIndex.from_arrays([pd.CategoricalIndex(visits.index.get_level_values(0).astype(str), name='visit'), visits.index.get_level_values('id')]))\n",
    "                self.visits[filt][tract] = visits\n",
    "\n",
    "    def write_tables(self, path, filt, sample=None):\n",
    "        p = Path(path)\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        h5_file = p.joinpath(f'{filt}.h5')\n",
    "\n",
    "        for table, v1 in self.tables[filt].items():\n",
    "            for tract in v1.keys():\n",
    "                df = self.tables[filt][table][tract]\n",
    "                if sample:\n",
    "                    df = df.sample(sample)\n",
    "                df.to_hdf(h5_file, f'{table}_{tract}')\n",
    "\n",
    "        for tract in self.visits[filt].keys():\n",
    "            self.visits[filt][tract].to_hdf(h5_file, f'visits_{tract}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_folder(path):\n",
    "    \"\"\"Given a folder return available tracts and filters\n",
    "    \"\"\"\n",
    "    folder = Path(path)\n",
    "    tracts = list(set([int(t.name.split('-')[-1]) for t in folder.rglob('*tract*')]))\n",
    "    filters = [f.name for f in folder.joinpath('plots').iterdir() if f.is_dir()]\n",
    "\n",
    "    return tracts, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/project/tmorton/tickets/DM-20015/RC2_w18'\n",
    "tracts, filters = scan_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['analysisCoaddTable_forced', 'analysisCoaddTable_unforced', 'visitMatchTable']\n",
    "tracts = ['9697', '9813', '9615']\n",
    "filters = ['HSC-R', 'HSC-Z', 'HSC-I', 'HSC-G'] #, 'HSC-Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.fetch_tables(tables=tables, tracts=tracts, filters=filters, sample=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.fetch_visits(tracts=tracts, filters=filters, sample=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filt in filters:\n",
    "    d.write_tables('tmp', filt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
